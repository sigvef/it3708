\documentclass[a4paper]{article}

\usepackage[utf8]{inputenc}
\usepackage{fancyhdr}
\usepackage{float}
\usepackage{graphicx}
\usepackage{varioref}
\usepackage{url}
\usepackage[margin=1em]{subfig}
\usepackage{pgfplots}
\usepackage{tikz}
\usetikzlibrary{arrows}
\usetikzlibrary{positioning}
\pagestyle{fancy}
\graphicspath{{img/}}
\renewcommand\thepart{\Alph{part}}
\pgfplotsset{compat=1.5}

\newcommand\TODO[1]{\textcolor{red}{TODO:#1}}
\newcommand\todo[1]{\TODO{#1}}

\title{Homework Module: A Controller for Swarm Behaviour in Webots}

\lhead{Homework Module \#1}
\rhead{IT3708 - Subsymbolic Methods in AI}

\author{
    Aleksander Burkow \\
    Sigve Sebstian Farstad \\
    Emil Gr√∏nnbeck
}

\begin{document}
\pagenumbering{roman}

\maketitle
\thispagestyle{empty}

\abstract{
This report presents a solution for Homework Module \#1 of IT3708, spring 2014 at NTNU.
The purpose of the homework module is to ``understand swarm behaviour by implementing a controller for box pushing task in Webots''~\cite{assignment}.
}

\newpage

\tableofcontents

\newpage
\setcounter{page}{1}
\pagenumbering{arabic}

\part{Introduction}
\label{part:proposed-system}

``Swarm robotics is a field that capitalizes on self-organization to generate interesting global patterns from interactions among relatively simple robots, all in the absence of centralized control.''~\cite{course-page}

This report presents three homogeneous robotic swarm that can identify interesting objects and push them to desired areas.
The individual agent is inspired by ant behaviour.

Three different versions of the swarm agent is presented: the proposed agent, the improved agent and the advanced agent.



\section{Subsumption Architecture}
The implemented system is based on an AI concept called subsumption.
The subsumption architecture was first described by Rodney Brooks in 1986~\cite{brooks}, and is also called Brooks' Architecture.
The idea behind Brooks' Architecture is inspired by insect behaviour.
Insects, although they have relatively small amounts of computational power, are able to walk, avoid obstacles, and make complex decisions at impressive speeds.
The architecture is divided into behavioural layers called: "the levels of competence".\cite{mwarnerwu}.
Each layer is independent of the others, but the higher levels are capable of overriding the lower.~\cite{mwarnerwu}
This way, complex behaviour can be composed of many small reactive agent behaviours.

\section{Webots}

``Webots is a development environment used to model, program and simulate mobile robots.''~\cite{webots}
Webots is used in this assignment to implement and simulate swarm agents.

\section{The E-puck}

The e-puck is a small (7 cm) open-source differential wheeled puck-shaped educational robot.
The E-puck model is available in Webots as a simulatable model, and it is used in this assignment as the hardware on which the swarm agents will run.

\part{The Proposed System}
\label{part:improved-system}

\section{Description}

The initial proposed system is based on the subsumption approach suggested in \cite{assignment}.
The "levels of competence" are divided into six independent behaviours: Wander, Avoid obstacles, Converge, Retrieve, and Reposition.
The lower levels have a higher priority and are able to override the higher ones.
Figure \vref{figure:subsumption} shows the subsumption hierarchy.

\input{subsumption.tex}

\subsection{Behaviours}
Each of the behaviours of the proposed system are independent reactive behaviours that map input sensor data to output actuators. The rest of this section describes each of the behaviours in detail.

\subsubsection{Wander}
Wander is the default behaviour.
It tells the agent to move straight forward as fast as possible, regardless of input.

\subsubsection{Avoid obstacles}
This behaviour is intended to save the agent from harmful collisions.
It is triggered when the agent's proximity sensors rise above a certain threshold, indicating that it's close to or about to hit a wall.
The rotational angle of the agent is then set proportional to the difference between the amount of obstacles on either side of the agent.
The closer the wall is on the right side, the harder the agent will turn to the left, and vice versa.
This technique is called Braitenberg avoidance~\cite{braitenberg}.

\subsubsection{Converge}
This behaviour is intended to let agents converge on a food location.
It is triggered when the sum of the agent's light sensors rise above a certain threshold, indicating that food is nearby.
The rotational angle of the agent is set in proportion to the amount of light on either side, making the agent heads towards the food, aligning it with the surface normal of the food for maximum force.

\subsubsection{Retrieve}
This behaviour is intended to let agents push food to a goal area, and is triggered when the agent detects that food is right in front of it.
It will try to align the agent with the surface-normal of the object, such that maximum force will be exerted upon it.
It subsumes the obstacle avoidance behaviour, letting the agent push the food.

\subsubsection{Reposition}
This behaviour is intended to let agents to move out of potentially poor retrieval positions.
It is enabled when the agent has found food, and is trying to bring it home.

A problem that commonly occurs is that the agents are trying to push the food from opposing sides, and therefore getting nowhere.
The reposition behaviour simply says that after $ N $ seconds of retrieval, the agent will try to push somewhere else nearby.
This exponential backoff-inspired behaviour allows the agents to reposition themselves reasonably efficiently.

\section{Simulation Results}
\label{section:first-sim-results}

This first version of the swarm agent, dubbed the proposed agent, was run in a series of simulation experiments in Webots.
7 swarm robots were randomly placed in a $ 1.5m \times 1.5m $ square world together with a randomly placed lit food block.
For each experiment, the time taken from world setup was complete until the swarm managed to transport the food to an edge of the world was measured.

This simulation was run 75 times.
The results of the simulation can be seen in figure \vref{figure:first-hist}.

\subsection{Observed weaknesses}

During observation of the 75 simulation runs, several weaknesses of the agent system were identified; amongst them: low levels of emergent teamwork, and getting stuck.

\subsubsection{No incentive for teamwork}
In the current architecture, the reposition behaviour blindly sends the robot away after it has been pushing the food for a fixed amount of time.
This does not entice teamwork, as robots who by chance are pushing on the same side have equal chance of repositioning themselves as robots who are blindly pushing from some unproductive angle.
The result is that the robots don't intentionally cluster together, making food retrieval more luck-of-the-draw based than a coordinated operation.

\subsubsection{Getting stuck}
In this implementation, the robots had a tendency to get stuck in a few different ways. Fortunately these issues mainly manifested themselves after the pushing of the box into the wall, therefore not interfering with the goal.

The stuck robots would typically get stuck in one of these ways:

\begin{itemize}
	\item Two robots driving straight into each other
	\item Getting stuck behind boxes
	\item Poor sensor calibration sometimes leads to robots not avoiding walls when food is nearby
    \item Rolling on their sides (rare)
\end{itemize}

\part{An Improved System}

\section{Description}
The initial system had some issues with enticing teamwork and preventing robots from having love affairs with one another instead of retrieving food for the starving epuck-population at home.

To resolve these issues, rewards for collaboration when retrieving food was introroduced.
Contingency behaviour when stuck was not implemented for the improved system, as agents getting stuck after the food had reached the goal area did obviously not interfere with achieving the goal.

\subsection{The improved reposition behaviour}
The reposition behaviour has been modified to reward agents working together. This is done by increasing the allotted retrieval-time in proportion to the number of neighbouring robots.

Allowing robots to push for longer periods of time in the vicinity of neighbours tends to converge them together on the same side. Robots trying to go solo will reposition themselves until they realign with the rest of the pack.

The improved behaviour had a noticeable effect on the average running time of our simulations, as shown in the graphs below.

\section{Simulation Results}
This version of the swarm agent was run in a series of simulation experiments in Webots identical to the simulations in section \vref{section:first-sim-results}.

This simulation was run 75 times.
The results of the simulation can be seen in figure \vref{figure:second-hist}.

As hoped, the improved system presents a considerable improvement over the original system presented in part \vref{part:proposed-system}.
Indeed, the median completion time of the improved swarm agent is almost halved from the original agent, bringing it down to a somewhat impressive $ 21.344 $ seconds.

\part{A More Advanced Architecture}
\label{part:advanced-system}

\section{Description}

Exploring the viability of the improved swarm agent from part \vref{part:improved-system} in different environments, a two-food scenario is considered.
In this scenario there are two food boxes that need to be collected by the swarm.

Adapting the improved swarm agent from part \ref{part:improved-system}, a new behaviour is added to the subsumption ladder: an anti-stagnation behaviour called unstick.
An overview of the behaviour subsumption scheme for the advanced system can be found in figure \vref{figure:advanced-subsumption}.

\subsection{Unstick}
This behaviour is implemented to introduce jiggle to the system. It is triggered at random, and when triggered, subsumes all other behaviours. 

\input{advanced-subsumption.tex}

\section{Simulation Results}

These two versions of the swarm agent was run in a series of simulation experiments in Webots. The simulation setup was nearly identical to the setup in section \vref{section:first-sim-results}, with the exception being that there were two independent but identical lit food boxes instead of one.

This simulation was run 75 times with the improved swarm agent presented in part \vref{part:improved-system}, and 75 times with the advanced system with the unstick behaviour presented in part \vref{part:advanced-system}.
The results from these simulations can be seen in figure \vref{figure:third-hist} and figure \vref{figure:fourth-hist}, respectively.

The simulations with the improved agent from part \ref{part:improved-system}, without the unstick behaviour, were dominated by runs where the swarm was not able to complete its task.
Often the swarm would get stuck in a locked position, and the simulation would have to be aborted prematurely.

In the simulations where the swarm did finish their task, they finished quite quickly - using only one third of the time of the advanced system with the unstuck behaviour.
This is a clear example of survivorship bias.

The simulations with the advanced agent from \ref{part:advanced-system}, with the unstick behaviour, fared much better.
The median solution time for the advanced agent in the simulations was $ 647.872 $ seconds.
Of these seconds, the vast majority were typically spent finding and moving the second food box.

\input{measurements/histogram.tex}

\newpage
\pagenumbering{gobble}
\bibliography{reference-library}
\bibliographystyle{plain}

\end{document}
